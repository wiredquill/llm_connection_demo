apiVersion: v1
kind: Service
metadata:
  name: ollama-service # This is the name your chat app will use to connect (OLLAMA_BASE_URL)
  namespace: llm-connection # Ensure this is the same namespace
  labels:
    app: ollama
spec:
  selector:
    app: ollama # Selects the Pods managed by the Ollama Deployment
  ports:
  - name: http
    protocol: TCP
    port: 11434 # The port the service will expose
    targetPort: 11434 # The port on the Ollama Pods
  type: ClusterIP # Exposes the service on an internal IP in the cluster.
                 # This is usually sufficient if only other pods in the cluster need to access it.
